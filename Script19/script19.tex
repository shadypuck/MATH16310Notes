\documentclass[../main.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter}{}}
\setcounter{chapter}{18}

\begin{document}




\chapter[Differentiation in \texorpdfstring{$\protect\fakeboldb{\R}^{\bm{n}}$}{TEXT}]{Differentiation in \texorpdfstring{$\protect\fakeboldc{\R}^{\bm{n}}$}{TEXT}}\label{sct:19}
\begin{definition}\label{dfn:19.1}\marginnote{8/4:}
    A \textbf{linear transformation} $\varphi:\R^n\to\R^m$ is a function such that for any $\x,\y\in\R^n$ and for any $\lambda\in\R$,
    \begin{enumerate}[label={(\alph*)}]
        \item $\varphi(\x+\y)=\varphi(\x)+\varphi(\y)$;
        \item $\varphi(\lambda\x)=\lambda\varphi(\x)$.
    \end{enumerate}
    That is, $\varphi$ is a linear transformation if it respects the two operations in Definition \ref{dfn:18.2}.
\end{definition}

\begin{lemma}\label{lem:19.2}
    Let $\varphi:\R^n\to\R^m$ be a linear transformation. Then $\varphi(\mathbf{0})=\mathbf{0}$.
    \begin{proof}
        Suppose for the sake of contradiction that $\varphi(\mathbf{0})\neq\mathbf{0}$. Then
        \begin{align*}
            \mathbf{0} &= \varphi(\x)-\varphi(\x)\\
            &= \varphi(\x-\x)\tag*{Definition \ref{dfn:19.1}}\\
            &= \varphi(\mathbf{0})\\
            &\neq \mathbf{0}
        \end{align*}
        a contradiction.
    \end{proof}
\end{lemma}

\begin{exercise}\label{exr:19.3}
    We denote $\x\in\R^2$ by $\x=(x,y)$. Determine whether the following functions are linear transformations:
    \begin{enumerate}[label={(\alph*)}]
        \item $\varphi:\R^2\to\R$, $\varphi(x,y)=x+y$.
        \begin{proof}[Answer]
            $\varphi$ is a linear transformation.
        \end{proof}
        \begin{proof}
            To prove that $\varphi$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^2$ and for any $\lambda\in\R$, $\varphi(\x+\y)=\varphi(\x)+\varphi(\y)$ and $\varphi(\lambda\x)=\lambda\varphi(\x)$. Let $\x,\y$ be arbitrary elements of $\R^2$, and let $\lambda$ be an arbitrary element of $\R$. Then
            \begin{align*}
                \varphi(\x+\y) &= (x_1+y_1)+(x_2+y_2)\\
                &= (x_1+x_2)+(y_1+y_2)\\
                &= \varphi(\x)+\varphi(\y)
            \end{align*}
            and
            \begin{align*}
                \varphi(\lambda\x) &= \lambda x_1+\lambda x_2\\
                &= \lambda(x_1+x_2)\\
                &= \lambda\varphi(\x)
            \end{align*}
            as desired.
        \end{proof}
        \item $\varphi:\R^2\to\R^2$, $\varphi(x,y)=(x,y+1)$.
        \begin{proof}[Answer]
            $\varphi$ is not a linear transformation.
        \end{proof}
        \begin{proof}
            By the definition of $\varphi$, $\varphi(\mathbf{0})=(0,1)\neq\mathbf{0}$. Thus, by the contrapositive of Lemma \ref{lem:19.2}, $\varphi$ is not a linear transformation, as desired.
        \end{proof}
        \item $\varphi:\R^2\to\R^3$, $\varphi(x,y)=(3x-y,x+2y,0)$.
        \begin{proof}[Answer]
            $\varphi$ is a linear transformation.
        \end{proof}
        \begin{proof}
            To prove that $\varphi$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^2$ and for any $\lambda\in\R$, $\varphi(\x+\y)=\varphi(\x)+\varphi(\y)$ and $\varphi(\lambda\x)=\lambda\varphi(\x)$. Let $\x,\y$ be arbitrary elements of $\R^2$, and let $\lambda$ be an arbitrary element of $\R$. Then
            \begin{align*}
                \varphi(\x+\y) &= (3[x_1+y_1]-[x_2+y_2],[x_1+y_1]+2[x_2+y_2],0)\\
                &= ([3x_1-x_2]+[3y_1-y_2],[x_1+2x_2]+[y_1+2y_1],0)\\
                &= (3x_1-x_2,x_1+2x_2,0)+(3y_1-y_2,y_1+2y_2,0)\\
                &= \varphi(\x)+\varphi(\y)
            \end{align*}
            and
            \begin{align*}
                \varphi(\lambda\x) &= (3[\lambda x_1]-[\lambda x_2],[\lambda x_1]+2[\lambda x_2],0)\\
                &= (\lambda[3x_1-x_2],\lambda[x_1+2x_2],0)\\
                &= \lambda(3x_1-x_2,x_1+2x_2,0)\\
                &= \lambda\varphi(\x)
            \end{align*}
            as desired.
        \end{proof}
        \item $\varphi:\R^2\to\R^3$, $\varphi(x,y)=(x^2,x+y,x+y^3)$.
        \begin{proof}[Answer]
            $\varphi$ is not a linear transformation.
        \end{proof}
        \begin{proof}
            Consider $(1,1)\in\R^2$ and let $2\in\R$. Then
            \begin{align*}
                \varphi(2(1,1)) &= (4,4,10)\\
                &\neq (2,4,4)\\
                &= 2(1,2,2)\\
                &= 2\varphi(1,1)
            \end{align*}
            as desired.
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{exercise}\label{exr:19.4}\leavevmode
    \begin{enumerate}[label={(\alph*)}]
        \item Let $\varphi:\R\to\R$ be a linear transformation. What does the graph of $\varphi$ look like?
        \begin{proof}[Answer]
            A line through the origin with finite slope.
        \end{proof}
        \item Let $\varphi:\R^2\to\R$ be a linear transformation. What does the graph of $\varphi$ look like?
        \begin{proof}[Answer]
            A plane through the origin with finite slope in both directions.
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{exercise}\label{exr:19.5}\leavevmode
    \begin{enumerate}[label={(\alph*)}]
        \item Let $\varphi:\R^n\to\R^m$ and $\psi:\R^m\to\R^\ell$ be linear transformations. Prove that $\psi\circ\varphi$ is also a linear transformation.
        \begin{proof}
            To prove that $\psi\circ\varphi:\R_n\to\R^\ell$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^n$ and for any $\lambda\in\R$, $(\psi\circ\varphi)(\x+\y)=(\psi\circ\varphi)(\x)+(\psi\circ\varphi)(\y)$ and $(\psi\circ\varphi)(\lambda\x)=\lambda(\psi\circ\varphi)(\x)$. Let $\x,\y$ be arbitrary elements of $\R^n$, and let $\lambda$ be an arbitrary element of $\R$. Then since $\varphi$ and $\psi$ are linear transformations themselves, we have that
            \begin{align*}
                (\psi\circ\varphi)(\x+\y) &= \psi(\varphi(\x+\y))\\
                &= \psi(\varphi(\x)+\varphi(\y))\tag*{Definition \ref{dfn:19.1}}\\
                &= \psi(\varphi(\x))+\psi(\varphi(\y))\tag*{Definition \ref{dfn:19.1}}\\
                &= (\psi\circ\varphi)(\x)+(\psi\circ\varphi)(\y)
            \end{align*}
            and
            \begin{align*}
                (\psi\circ\varphi)(\lambda\x) &= \psi(\varphi(\lambda\x))\\
                &= \psi(\lambda\varphi(\x))\tag*{Definition \ref{dfn:19.1}}\\
                &= \lambda\psi(\varphi(\x))\tag*{Definition \ref{dfn:19.1}}\\
                &= \lambda(\psi\circ\varphi)(\x)
            \end{align*}
            as desired.
        \end{proof}
        \item Let $\varphi,\psi:\R^n\to\R^m$ be linear transformations and let $\lambda\in\R$. Prove that $\varphi+\psi$ and $\lambda\varphi$ are linear transformations.
        \begin{proof}
            To prove that $\varphi+\psi$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^n$ and for any $\lambda\in\R$, $(\varphi+\psi)(\x+\y)=(\varphi+\psi)(\x)+(\varphi+\psi)(\y)$ and $(\varphi+\psi)(\lambda\x)=\lambda(\varphi+\psi)(\x)$. Let $\x,\y$ be arbitrary elements of $\R^n$, and let $\lambda$ be an arbitrary element of $\R$. Then since $\varphi$ and $\psi$ are linear transformations themselves, we have that
            \begin{align*}
                (\varphi+\psi)(\x+\y) &= \varphi(\x+\y)+\psi(\x+\y)\\
                &= \varphi(\x)+\varphi(\y)+\psi(\x)+\psi(\y)\tag*{Definition \ref{dfn:19.1}}\\
                &= \varphi(\x)+\psi(\x)+\varphi(\y)+\psi(\y)\\
                &= (\varphi+\psi)(\x)+(\varphi+\psi)(\y)
            \end{align*}
            and
            \begin{align*}
                (\varphi+\psi)(\lambda\x) &= \varphi(\lambda\x)+\psi(\lambda\x)\\
                &= \lambda\varphi(\x)+\lambda\psi(\x)\tag*{Definition \ref{dfn:19.1}}\\
                &= \lambda(\varphi(\x)+\psi(\x))\\
                &= \lambda(\varphi+\psi)(\x)
            \end{align*}
            as desired.\par\smallskip
            To prove that $\lambda\varphi$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^n$ and for any $\gamma\in\R$, $(\lambda\varphi)(\x+\y)=(\lambda\varphi)(\x)+(\lambda\varphi)(\y)$ and $(\lambda\varphi)(\gamma\x)=\gamma(\lambda\varphi)(\x)$. Let $\x,\y$ be arbitrary elements of $\R^n$, and let $\gamma$ be an arbitrary element of $\R$. Then since $\varphi$ is a linear transformation itself, we have that
            \begin{align*}
                (\lambda\varphi)(\x+\y) &= \lambda\varphi(\x+\y)\\
                &= \lambda(\varphi(\x)+\varphi(\y))\tag*{Definition \ref{dfn:19.1}}\\
                &= \lambda\varphi(\x)+\lambda\varphi(\y)\\
                &= (\lambda\varphi)(\x)+(\lambda\varphi)(\y)
            \end{align*}
            and
            \begin{align*}
                (\lambda\varphi)(\gamma\x) &= \lambda\varphi(\gamma\x)\\
                &= \lambda\gamma\varphi(\x)\tag*{Definition \ref{dfn:19.1}}\\
                &= \gamma\lambda\varphi(\x)\\
                &= \gamma(\lambda\varphi)(\x)
            \end{align*}
            as desired.
        \end{proof}
        \item Let $\pi_I:\R^m\to\R^k$ be the projection function from Definition \ref{dfn:18.34}. Prove that $\pi_I$ is a linear transformation.
        \begin{proof}
            To prove that $\pi_I$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^n$ and for any $\lambda\in\R$, $\pi_I(\x+\y)=\pi_I(\x)+\pi_I(\y)$ and $\pi_I(\lambda\x)=\lambda\pi_I(\x)$. Let $\x,\y$ be arbitrary elements of $\R^n$, and let $\lambda$ be an arbitrary element of $\R$. Then we have that
            \begin{align*}
                \pi_I(\x+\y) &= (x_{i_1}+y_{i_k},\dots,x_{i_k}+y_{i_k})\\
                &= (x_{i_1},\dots,x_{i_k})+(y_{i_1},\dots,y_{i_k})\\
                &= \pi_I(\x)+\pi_I(\y)
            \end{align*}
            and
            \begin{align*}
                \pi_I(\lambda\x) &= (\lambda x_{i_1},\dots,\lambda x_{i_k})\\
                &= \lambda(x_{i_1},\dots,x_{i_k})\\
                &= \lambda\pi_I(\x)
            \end{align*}
            as desired.
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{definition}\label{dfn:19.6}
    The \textbf{$\bm{j^\text{th}}$ standard basis vector} in $\R^n$ is the vector $\mathbf{e}_j$ defined by
    \begin{equation*}
        (\mathbf{e}_j)_k =
        \begin{cases}
            1 & k=j\\
            0 & k\neq j
        \end{cases}
    \end{equation*}
\end{definition}

For example, the standard basis vectors for $\R^3$ are $\mathbf{e}_1=(1,0,0)$, $\mathbf{e}_2=(0,1,0)$, and $\mathbf{e}_3=(0,0,1)$. Notice that if $\x=(x_1,\dots,x_n)\in\R^n$, then $\x=x_1\mathbf{e}_1+\cdots+x_n\mathbf{e}_n$.

\begin{definition}\label{dfn:19.7}
    For any linear transformation $\varphi:\R^n\to\R^m$, we denote by $[\varphi]_{ij}$ the $i^\text{th}$ component of the vector $\varphi(\mathbf{e}_j)$; i.e., $[\varphi]_{ij}=\varphi_i(\mathbf{e}_j)$.
\end{definition}

\begin{exercise}\label{exr:19.8}\leavevmode
    \begin{enumerate}[label={(\alph*)},ref={\theexercise\alph*}]
        \item \label{exr:19.8a}Let $\varphi:\R^n\to\R^m$ be a linear transformation and let $\x\in\R^n$. Find a formula for $\varphi(\x)$ in terms of $[\varphi]_{ij}$, the components of $\x$, and the standard basis vectors in $\R^m$.
        \begin{proof}
            Since $\x=x_1\mathbf{e}_1+\cdots+x_n\mathbf{e_n}$ by Definition \ref{dfn:19.6} and since $\varphi$ is linear, we have that
            \begingroup
            \allowdisplaybreaks
            \begin{align*}
                \varphi(\x) &= \varphi(x_1\mathbf{e}_1+\cdots+x_n\mathbf{e_n})\\
                &= \varphi(x_1\mathbf{e}_1)+\cdots+\varphi(x_n\mathbf{e}_n)\\
                &= x_1\varphi(\mathbf{e}_1)+\cdots+x_n\varphi(\mathbf{e}_n)\\
                &= x_1(\varphi_1(\mathbf{e}_1)\mathbf{e_1}+\cdots+\varphi_m(\mathbf{e}_1)\mathbf{e_m})+\cdots+x_n(\varphi_1(\mathbf{e}_n)\mathbf{e_1}+\cdots+\varphi_m(\mathbf{e}_n)\mathbf{e_m})\\
                &= x_1([\varphi]_{11}\mathbf{e_1}+\cdots+[\varphi]_{m1}\mathbf{e_m})+\cdots+x_n([\varphi]_{1n}\mathbf{e_1}+\cdots+[\varphi]_{mn}\mathbf{e_m})\\
                &= x_1\sum_{i=1}^m[\varphi]_{i1}\mathbf{e}_i+\cdots+x_n\sum_{i=1}^m[\varphi]_{in}\mathbf{e}_i\\
                &= \sum_{j=1}^nx_j\sum_{i=1}^m[\varphi]_{ij}\mathbf{e}_i\\
                &= \sum_{i=1}^m\sum_{j=1}^nx_j[\varphi]_{ij}\mathbf{e}_i
            \end{align*}
            \endgroup
        \end{proof}
        \item \label{exr:19.8b}For $1\leq i\leq m$ and $1\leq j\leq n$, let $A_{ij}\in\R$. Prove that there is a unique linear transformation $\varphi:\R^n\to\R^m$ such that $[\varphi]_{ij}=A_{ij}$ for all $i,j$.
        \begin{proof}
            Let $\varphi$ be defined by
            \begin{equation*}
                \varphi(\x) = \sum_{i=1}^m\sum_{j=1}^nx_jA_{ij}\mathbf{e}_i
            \end{equation*}
            for all $\x\in\R^n$. Thus, by Definition \ref{dfn:19.7}, $[\varphi]_{ij}=A_{ij}$ for all $i,j$.\par
            To prove that $\varphi$ is a linear transformation, Definition \ref{dfn:19.1} tells us that it will suffice to show that for any $\x,\y\in\R^n$ and $\lambda\in\R$, $\varphi(\x+\y)=\varphi(\x)+\varphi(\y)$ and $\varphi(\lambda\x)=\lambda\varphi(\x)$. Let $\x,\y$ be arbitrary elements of $\R^n$. Then
            \begin{align*}
                \varphi(\x+\y) &= \sum_{i=1}^m\sum_{j=1}^n(x_j+y_j)A_{ij}\mathbf{e}_i\\
                &= \sum_{i=1}^m\sum_{j=1}^n(x_jA_{ij}\mathbf{e}_i+y_jA_{ij}\mathbf{e}_i)\\
                &= \sum_{i=1}^m\sum_{j=1}^nx_jA_{ij}\mathbf{e}_i+\sum_{i=1}^m\sum_{j=1}^ny_jA_{ij}\mathbf{e}_i\\
                &= \varphi(\x)+\varphi(\y)
            \end{align*}
            and
            \begin{align*}
                \varphi(\lambda\x) &= \sum_{i=1}^m\sum_{j=1}^n(\lambda x_j)A_{ij}\mathbf{e}_i\\
                &= \lambda\sum_{i=1}^m\sum_{j=1}^nx_jA_{ij}\mathbf{e}_i\\
                &= \lambda\varphi(\x)
            \end{align*}
            as desired.\par
            Let $\psi:\R^n\to\R^m$ be any linear transformation satisfying $[\psi]_{ij}=A_{ij}$ for all $i,j$. To prove that $\varphi=\psi$, it will suffice to show that $\varphi(\x)=\psi(\x)$ for all $\x\in\R^n$. Let $\x$ be an arbitrary element of $\R^n$. Then
            \begin{align*}
                \varphi(\x) &= \sum_{i=1}^m\sum_{j=1}^nx_jA_{ij}\mathbf{e}_i\\
                &= \sum_{i=1}^m\sum_{j=1}^nx_j[\psi]_{ij}\mathbf{e}_i\tag*{Exercise \ref{exr:19.8a}}\\
                &= \psi(\x)
            \end{align*}
            as desired.
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{definition}\label{dfn:19.9}
    We define an $m\times n$ matrix $M$ to be an array of scalars
    \begin{equation*}
        M = \{a_{ij}\} =
        \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n}\\
            a_{21} & a_{22} & \cdots & a_{2n}\\
            \vdots & \vdots & \ddots & \vdots\\
            a_{m1} & a_{m2} & \cdots & a_{mn}\\
        \end{bmatrix}
    \end{equation*}
\end{definition}

So $a_{ij}$ denotes the scalar in row $i$, column $j$ of the matrix. For every linear transformation $\varphi:\R^n\to\R^m$, there is a corresponding $m\times n$ matrix $\{[\varphi]_{ij}\}$. We denote $\{[\varphi]_{ij}\}$ by $[\varphi]$. Also, by Exercise \ref{exr:19.8}, given a matrix of scalars, there is a unique linear transformation $\varphi:\R^n\to\R^m$ that corresponds to it.

\begin{exercise}\label{exr:19.10}\leavevmode
    \begin{enumerate}[label={(\alph*)}]
        \item Let $\varphi:\R^3\to\R^2$ be given by $\varphi(x,y,z)=(3x+2y-z,4x-5y+2z)$. Write down the matrix $[\varphi]$.
        \begin{proof}[Answer]
            The matrix is
            \begin{equation*}
                M =
                \begin{bmatrix}
                    3 & 2 & -1\\
                    4 & -5 & 2\\
                \end{bmatrix}
            \end{equation*}
        \end{proof}
        \item What is the linear transformation that corresponds to the following matrix?
        \begin{equation*}
            \begin{bmatrix}
                -2 & 3\\
                4 & 6\\
                1 & 0\\
            \end{bmatrix}
        \end{equation*}
        \begin{proof}[Answer]
            The linear transformation is $\varphi:\R^2\to\R^3$ defined by
            \begin{equation*}
                \varphi(x,y) = (-2x+3y,4x+6y,x)
            \end{equation*}
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{theorem}\label{trm:19.11}
    Let $\varphi:\R^n\to\R^m$ be a linear transformation. Then there is a constant $M_\varphi\in\R$ such that for all $\x\in\R^n$, we have $\norm{\varphi(\x)}\leq M_\varphi\norm{\x}$.
    \begin{lemma*}\leavevmode
        Let $a_1,\dots,a_n\in\R$. Then
        \begin{equation*}
            \left( \sum_{i=1}^na_i \right)^2 \leq n\sum_{i=1}^na_i^2
        \end{equation*}
        \begin{proof}[Proof]
            We have that
            \begin{align*}
                \left( \sum_{i=1}^na_i \right)^2 &= \left( 1a_1+\cdots+1a_n \right)^2\\
                &\leq \left( \sqrt{1^2+\cdots+1^2}\cdot\sqrt{a_1^2+\cdots+a_n^2} \right)^2\tag*{Lemma \ref{lem:18.9b}}\\
                &= \sqrt{n}^2\sqrt{\sum_{i=1}^na_i^2}^2\\
                &= n\sum_{i=1}^na_i^2
            \end{align*}
            as desired.
        \end{proof}
    \end{lemma*}
    \begin{proof}[Proof of Theorem \ref{trm:19.11}]
        Let
        \begin{align*}
            M &= \max_{i,j}|[\varphi]_{ij}|&
            M_\varphi &= M\sqrt{nm}
        \end{align*}
        Then
        \begin{align*}
            \norm{\varphi(\x)} &= \sqrt{\sum_{i=1}^m\left( \sum_{j=1}^nx_j[\varphi]_{ij} \right)^2}\\
            &\leq \sqrt{\sum_{i=1}^mn\sum_{j=1}^n(x_j[\varphi]_{ij})^2}\tag*{Lemma}\\
            &= \sqrt{n}\cdot\sqrt{\sum_{i=1}^m\sum_{j=1}^nx_j^2[\varphi]_{ij}^2}\\
            &= \sqrt{n}\cdot\sqrt{\sum_{j=1}^n\left( x_j^2\sum_{i=1}^m[\varphi]_{ij}^2 \right)}\\
            &\leq \sqrt{n}\cdot\sqrt{\sum_{j=1}^n\left( x_j^2\sum_{i=1}^mM^2 \right)}\\
            &= \sqrt{n}\cdot\sqrt{\sum_{j=1}^nmM^2x_j^2}\\
            &= M\sqrt{nm}\cdot\sqrt{\sum_{j=1}^nx_j^2}\\
            &= M_\varphi\norm{\x}\tag*{Definition \ref{dfn:18.6}}
        \end{align*}
        as desired.
    \end{proof}
\end{theorem}

\begin{corollary}\label{cly:19.12}\marginnote{\emph{8/7:}}
    Any linear transformation $\varphi:\R^n\to\R^m$ is uniformly continuous.
    \begin{proof}
        To prove that $\varphi$ is uniformly continuous, Definition \ref{dfn:18.42} tells us that it will suffice to show that for every $\epsilon>0$, there exists $\delta>0$ such that if $\x,\y\in\R^n$ and $\norm{\x-\y}<\delta$, then $\norm{\varphi(\x)-\varphi(\y)}<\epsilon$. Let $\epsilon>0$ be arbitrary. Since $\varphi$ is a linear transformation, Theorem \ref{trm:19.11} asserts that there exists $M_\varphi\in\R$ such that $\norm{\varphi(\x)}\leq M_\varphi\norm{\x}$ for all $\x\in\R^n$. With this result, choose $\delta=\frac{\epsilon}{M_\varphi}$. Now let $\x,\y$ be arbitrary elements of $\R^n$ satisfying $\norm{\x-\y}<\delta$. Then
        \begin{align*}
            \norm{\varphi(\x)-\varphi(\y)} &= \norm{\varphi(\x-\y)}\tag*{Definition \ref{dfn:19.1}}\\
            &\leq M_\varphi\norm{\x-\y}\\
            &< M_\varphi\cdot\frac{\epsilon}{M_\varphi}\\
            &= \epsilon
        \end{align*}
        as desired.
    \end{proof}
\end{corollary}

\begin{lemma}\label{lem:19.13}
    Let $\varphi:\R^n\to\R^m$ be a linear transformation. If $\lim_{\h\to\mathbf{0}}\norm{\varphi(\h)}/\norm{\h}=0$, then $\varphi$ is the zero transformation, i.e., $\varphi(\x)=\mathbf{0}$ for all $\x$.
    \begin{proof}
        Suppose for the sake of contradiction that $\varphi(\x)\neq\mathbf{0}$ for some $\x\in\R^n$. Since $\varphi(\x)=\sum_{i=1}^m\sum_{j=1}^nx_j[\varphi]_{ij}\mathbf{e}_i\neq 0$ by Exercise \ref{exr:19.8}, there exists at least one nonzero $[\varphi]_{ab}$. Consequently, since $\lim_{\h\to\mathbf{0}}\norm{\varphi(\h)}/\norm{\h}=0$, Definition \ref{dfn:18.29} tells us that there exists $\delta>0$ such that if $\h\in\R^n$ and $0<\norm{\h-\mathbf{0}}<\delta$, then $|\norm{\varphi(\h)}/\norm{\h}-0|=\norm{\varphi(\h)}/\norm{\h}<|[\varphi]_{ab}|$. Let $\h=(0,\dots,0,h_b,0,\dots,0)$ where $0<h_b<\delta$. It follows that $0<\norm{\h-\mathbf{0}}<\delta$. Therefore, since
        \begin{align*}
            \norm{\varphi(\h)} &= \norm{\sum_{i=1}^m\sum_{j=1}^nh_j[\varphi]_{ij}\mathbf{e}_i}&
                \norm{\h} &= |h_b|\\
            &= \norm{\sum_{i=1}^mh_b[\varphi]_{ib}\mathbf{e}_i}\\
            &\geq \norm{h_b[\varphi]_{ab}\mathbf{e}_a}\\
            &= |h_b[\varphi]_{ab}|
        \end{align*}
        we have that
        \begin{align*}
            |[\varphi]_{ab}| &= \frac{|h_b[\varphi]_{ab}|}{|h_b|}\\
            &\leq \frac{\norm{\varphi(\h)}}{\norm{\h}}\\
            &< |[\varphi]_{ab}|
        \end{align*}
        a contradiction.
    \end{proof}
\end{lemma}

\begin{definition}\label{dfn:19.14}\marginnote{8/11:}
    A function $f:A\to\R^m$ is differentiable at a point $\mathbf{a}\in A$ if there exists a linear transformation $\varphi:\R^n\to\R^m$ such that
    \begin{equation*}
        \lim_{\h\to\mathbf{0}}\frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-\varphi(\h)}}{\norm{\h}}=0
    \end{equation*}
    When such a linear transformation $\varphi$ exists, it is called the \textbf{total derivative} (of $f$ at $\mathbf{a}$) and is denoted by $Df(\mathbf{a})$.
\end{definition}

\begin{remark}\label{rmk:19.15}
    For every $\mathbf{a}\in A$ at which $f$ is differentiable, $Df(\mathbf{a}):\R^n\to\R^m$ is a linear transformation defined on all of $\R^n$. In particular, $Df(\mathbf{a})(\x)$ is the derivative of $f$ at $\mathbf{a}\in A$, evaluated at $\x\in\R^n$.
\end{remark}

\begin{proposition}\label{prp:19.16}
    The derivative at $\mathbf{a}\in A$ of a function $f:A\to\R^m$ is unique. That is, if $\varphi$ and $\psi$ are two linear transformations that satisfy the limit of Definition \ref{dfn:19.14}, then $\varphi=\psi$. So, $Df(\mathbf{a})$ is well-defined.
    \begin{proof}
        Let $\varphi,\psi$ be linear transformations, each of which satisfies the limit of Definition \ref{dfn:19.14}. To prove that $\varphi=\psi$, it will suffice to show that $\varphi(\x)=\psi(\x)$ for all $\x\in\R^n$. To do so, Definition \ref{dfn:19.1} tells us that it will suffice to verify that $(\varphi-\psi)(\x)=\mathbf{0}$ for all $\x\in\R^n$. To do this, Lemma \ref{lem:19.13} tells us that it will suffice to confirm that $\lim_{\h\to\mathbf{0}}\norm{(\varphi-\psi)(\h)}/\norm{\h}=0$. Let's begin.\par
        To confirm that $\lim_{\h\to\mathbf{0}}\norm{(\varphi-\psi)(\h)}/\norm{\h}=0$, Definition \ref{dfn:18.29} tells us that it will suffice to demonstrate that for every $\epsilon>0$, there exists $\delta>0$ such that if $\h\in A$ and $0<\norm{\h}<\delta$, then $\norm{(\varphi-\psi)(\h)}/\norm{\h}<\epsilon$. Let $\epsilon>0$ be arbitrary. Since $\varphi$ and $\psi$ both satisfy the limit of Definition \ref{dfn:19.14}, Definition \ref{dfn:18.29} asserts that there exists a $\delta_1>0$ such that if $\h\in A$ and $0<\norm{\h}<\delta_1$, then
        \begin{equation*}
            \frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-\varphi(\h)}}{\norm{\h}} < \frac{\epsilon}{2}
        \end{equation*}
        and there exists a $\delta_2>0$ such that if $\h\in A$ and $0<\norm{\h}<\delta_2$, then
        \begin{equation*}
            \frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-\psi(\h)}}{\norm{\h}} < \frac{\epsilon}{2}
        \end{equation*}
        Choose $\delta=\min(\delta_1,\delta_2)$. Let $\h$ be an arbitrary element of $A$ satisfying $0<\norm{\h}<\delta$. Then
        \begin{align*}
            \frac{\norm{(\varphi-\psi)(\h)}}{\norm{\h}} &= \frac{\norm{\varphi(\h)-\psi(\h)}}{\norm{\h}}\tag*{Definition \ref{dfn:19.1}}\\
            &= \frac{\norm{\varphi(\h)-(f(\mathbf{a}+\h)-f(\mathbf{a}))}+\norm{(f(\mathbf{a}+\h)-f(\mathbf{a}))-\psi(\h)}}{\norm{\h}}\tag*{Corollary \ref{cly:18.11}}\\
            &= \frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-\varphi(\h)}}{\norm{\h}}+\frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-\psi(\h)}}{\norm{\h}}\tag*{Theorem \ref{trm:18.10}}\\
            &< \frac{\epsilon}{2}+\frac{\epsilon}{2}\\
            &= \epsilon
        \end{align*}
        as desired.
    \end{proof}
\end{proposition}

\begin{exercise}\label{exr:19.17}\leavevmode
    \begin{enumerate}[label={(\alph*)}]
        \item Let $f:A\to\R^m$ be a constant function, and $\mathbf{a}\in A$. Then $Df(\mathbf{a})=\mathbf{0}$. Note that here $\mathbf{0}$ represents the zero transformation.
        \begin{proof}
            Let $f(\x)=\y$ for all $\x\in A$. To prove that $Df(\mathbf{a})=\mathbf{0}$, Lemma \ref{lem:19.13} tells us that it will suffice to show that $\lim_{\h\to\mathbf{0}}\norm{Df(\mathbf{a})(\h)}/\norm{\h}=0$. But since $Df(\mathbf{a})$ exists by hypothesis, Definition \ref{dfn:19.14} implies that
            \begin{align*}
                0 &= \lim_{\h\to\mathbf{0}}\frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-Df(\mathbf{a})(\h)}}{\norm{\h}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{\y-\y-Df(\mathbf{a})(\h)}}{\norm{\h}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{-Df(\mathbf{a})(\h)}}{\norm{\h}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{Df(\mathbf{a})(\h)}}{\norm{\h}}\tag*{Theorem \ref{trm:18.10}}
            \end{align*}
            as desired.
        \end{proof}
        \item Let $f:\R^n\to\R^m$ be a linear transformation, and $\mathbf{a}\in\R^n$. Then $Df(\mathbf{a})=f$.
        \begin{proof}
            To prove that $Df(\mathbf{a})=f$, Definition \ref{dfn:19.1} and Lemma \ref{lem:19.13} tell us that it will suffice to show that $\lim_{\h\to\mathbf{0}}\norm{(f-Df(\mathbf{a}))(\h)}/\norm{\h}=0$. But since $Df(\mathbf{a})$ exists by hypothesis, Definition \ref{dfn:19.14} implies that
            \begin{align*}
                0 &= \lim_{\h\to\mathbf{0}}\frac{\norm{f(\mathbf{a}+\h)-f(\mathbf{a})-Df(\mathbf{a})(\h)}}{\norm{\h}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{f(\mathbf{a}+\h-\mathbf{a})-Df(\mathbf{a})(\h)}}{\norm{\h}}\tag*{Definition \ref{dfn:19.1}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{f(\h)-Df(\mathbf{a})(\h)}}{\norm{\h}}\\
                &= \lim_{\h\to\mathbf{0}}\frac{\norm{(f-Df(\mathbf{a}))(\h)}}{\norm{\h}}\tag*{Theorem \ref{trm:18.10}}
            \end{align*}
            as desired.
        \end{proof}
    \end{enumerate}
\end{exercise}

\begin{exercise}\label{exr:19.18}
    Let $f:\R\to\R$ and $a\in\R$. Show that $f$ is differentiable at $a$ in the sense of Definition \ref{dfn:19.14} if and only if $f$ is differentiable at $a$ in the sense of Definition \ref{dfn:12.1}. Show that if $f$ is differentiable at $a$ (in either sense), then $Df(a)(x)=f'(a)x$. Are these two uses of the word "differentiable" consistent?
    \begin{proof}
        Suppose first that $f$ is differentiable at $a$ in the sense of Definition \ref{dfn:19.14}, with total derivative $Df(a)$. To prove that $f$ is differentiable at $a$ in the sense of Definition \ref{dfn:12.1}, it will suffice to show that $\lim_{h\to 0}\frac{f(a+h)-f(a)}{h}=Df(a)(1)$. To do so, Definition \ref{dfn:11.1} tells us that it will suffice to verify that for every $\epsilon>0$, there exists a $\delta>0$ such that if $h\in\R$ and $0<|h|<\delta$, then $|\frac{f(a+h)-f(a)}{h}-Df(a)(1)|<\epsilon$. Let $\epsilon>0$ be arbitrary. Since $\lim_{h\to 0}\frac{|f(a+h)-f(a)-Df(a)(h)|}{|h|}=0$ by Definition \ref{dfn:19.14} and Remark \ref{rmk:18.8}, Definition \ref{dfn:11.1} asserts that there exists a $\delta$ such that if $h\in\R$ and $0<|h|<\delta$, then $|\frac{f(a+h)-f(a)-Df(a)(h)}{h}|<\epsilon$. Choose this $\delta$ to be our $\delta$. Let $h$ be an arbitrary element of $\R$ satisfying $0<|h|<\delta$. Then
        \begin{align*}
            \left| \frac{f(a+h)-f(a)}{h}-Df(a)(1) \right| &= \left| \frac{f(a+h)-f(a)-h\cdot Df(a)(1)}{h} \right|\\
            &= \left| \frac{f(a+h)-f(a)-Df(a)(h)}{h} \right|\tag*{Definition \ref{dfn:19.1}}\\
            &< \epsilon
        \end{align*}
        as desired.\par
        By a symmetric argument, we can suppose that $f$ is differentiable at $a$ in the sense of Definition \ref{dfn:12.1} and subsequently prove that $\lim_{h\to 0}\frac{\norm{f(a+h)-f(a)-f'(a)\cdot h}}{\norm{h}}=0$.\par
        By the proof of the forward direction and Definition \ref{dfn:12.1}, $f'(a)=Df(a)(1)$. It follows by Definition \ref{dfn:19.1} that
        \begin{align*}
            f'(a)x &= xDf(a)(1)\\
            &= Df(a)(x)
        \end{align*}
        as desired.
    \end{proof}
\end{exercise}

% \begin{theorem}\label{trm:19.19}
%     If $f:A\to\R^m$ is differentiable at $\mathbf{a}\in A$, then $f$ is continuous at $\mathbf{a}$.
%     \begin{proof}
%         To prove that $f$ is continuous at $\mathbf{a}$, Theorem \ref{trm:18.31} tells us that it will suffice to show that either $\mathbf{a}\notin LP(A)$ or $\lim_{\x\to\mathbf{a}}f(\x)=f(\mathbf{a})$. Since $f$ is differentiable at $\mathbf{a}\in A$, Definition 
%     \end{proof}
% \end{theorem}

% \begin{theorem}\label{trm:19.20}\leavevmode
%     \begin{enumerate}[label={\textup{(}\alph*\textup{)}}]
%         \item Let $f,g:A\to\R^m$ be differentiable at $\mathbf{a}\in A$. Then $f+g$ is differentiable at $\mathbf{a}$ and
%         \begin{equation*}
%             D(f+g)(\mathbf{a}) = Df(\mathbf{a})+Dg(\mathbf{a})
%         \end{equation*}
%         \item Let $f:A\to\R^m$ be differentiable at $\mathbf{a}\in A$ and let $\lambda\in\R$. Then $\lambda f$ is differentiable at $\mathbf{a}$ and
%         \begin{equation*}
%             D(\lambda f)(\mathbf{a}) = \lambda Df(\mathbf{a})
%         \end{equation*}
%     \end{enumerate}
% \end{theorem}

% \begin{theorem}[Chain Rule]\label{trm:19.21}
%     Let $f:A\to\R^m$ and $g:B\to\R^\ell$ be such that $f(A)\subset B\subset\R^m$. Suppose $f$ is differentiable at $\x\in A$ and $g$ is differentiable at $f(\x)$. Then $g\circ f$ is differentiable at $\x$ and
%     \begin{equation*}
%         D(g\circ f)(\x) = Dg(f(\x))\circ Df(\x)
%     \end{equation*}
% \end{theorem}

% \begin{remark}\label{rmk:19.22}\marginnote{8/18:}
%     Definition \ref{dfn:19.14} can be hard to work with. We now introduce partial derivatives which provide us with an easy way to compute derivatives, when we know that a function is differentiable (see Theorems \ref{trm:19.28} and \ref{trm:19.33}). We begin by considering real-valued functions $f:A\to\R$.
% \end{remark}

% \begin{definition}\label{dfn:19.23}
%     Let $f:A\to\R$ and let $\x\in A$. For any $1\leq j\leq n$, the limit
%     \begin{equation*}
%         \partial_jf(\x) = \lim_{h\to 0}\frac{f(\x+h\mathbf{e}_j)-f(\x)}{h}
%     \end{equation*}
%     if it exists, is called the \textbf{$\bm{j^\text{th}}$ partial derivative} (of $f$ at $a$).
% \end{definition}

% \begin{exercise}\label{exr:19.24}
%     Let $f:\R^2\to\R$. What is the geometric interpretation of $\partial_1f(\x)$ and $\partial_2f(\x)$.
% \end{exercise}

% \begin{proposition}\label{prp:19.25}
%     Let $f:A\to\R$. Let $\x\in A$ and let $\eta>0$ be such that $B(\x,\eta)\subset A$. Define $g:(-\eta,\eta)\to\R$ by $g(h)=f(\x+h\mathbf{e}_j)$. Fix $h_0\in(-\eta,\eta)$. Then $\partial_jf$ exists at $\x+h_0\mathbf{e}_j$ if and only if $g'$ exists at $h_0$. Moreover, if they both exist, then $\partial_jf(\x+h_0\mathbf{e}_j)=g'(h_0)$.
% \end{proposition}

% \begin{remark}\label{rmk:19.26}
%     In particular, Proposition \ref{prp:19.25} says that $\partial_jf(\x)$ exists if and only if $g'(0)$ exists. Moreover, if they exist, they are equal.
% \end{remark}

% \begin{exercise}\label{exr:19.27}
%     Use Proposition \ref{prp:19.25} to compute the following partial derivatives.
%     \begin{enumerate}[label={(\alph*)},ref={\theexercise\alph*}]
%         \item \label{exr:19.27a}Let $f:\R^3\to\R$ be defined by $f(\x)=\norm{\x}^2$. Let $\x\in\R^3$. Find $\partial_3f(\x)$.
%         \item \label{exr:19.27b}Let $G:\R^2\to\R$ be given by
%         \begin{equation*}
%             G(x,y) =
%             \begin{cases}
%                 \frac{xy}{x^2+y^2} & (x,y)\neq(0,0)\\
%                 0 & (x,y)=(0,0)
%             \end{cases}
%         \end{equation*}
%         Let $(a,b)\in\R^2$. Find $\partial_1G(a,b)$ and $\partial_2G(a,b)$.
%         \item \label{exr:19.27c}Let $H:\R^2\to\R$ be defined by $H(\x)=x_1^{1/3}x_2^{1/5}$. Find $\partial_1H(\mathbf{0})$ and $\partial_2H(\mathbf{0})$.
%         \begin{proof}
%             Undefined.
%         \end{proof}
%     \end{enumerate}
% \end{exercise}

% \begin{theorem}\label{trm:19.28}
%     If $f:A\to\R$ is differentiable at $\x\in A$, then the $j^\text{th}$ partial derivative $\partial_jf(\x)$ exists for every $1\leq j\leq n$. Moreover,
%     \begin{equation*}
%         [Df(\x)] =
%         \begin{bmatrix}
%             \partial_1f(\x) & \partial_2f(\x) & \cdots & \partial_nf(\x)
%         \end{bmatrix}
%     \end{equation*}
%     It follows that if $\x\in\R^n$, then
%     \begin{equation*}
%         Df(\x)(\y) = \sum_{j=1}^ny_j\partial_jf(\x)
%     \end{equation*}
%     (Hint: For the first part, use the chain rule.)
% \end{theorem}

% \begin{exercise}\label{exr:19.29}
%     Prove that $G$ and $H$ as in Exercises \ref{exr:19.27b} and \ref{exr:19.27c}, respectively, are not differentiable at $\mathbf{0}$. Deduce that the converse to Theorem \ref{trm:19.28} is false (see Remark \ref{rmk:19.35} and Theorem \ref{trm:19.36}).
% \end{exercise}

% \begin{exercise}\label{exr:19.30}
%     Suppose that $f,g:A\to\R$ are differentiable at $\x\in A$.
%     \begin{enumerate}[label={(\alph*)},ref={\theexercise\alph*}]
%         \item \label{exr:19.30a}Compute $\partial_j(f+g)(\x)$ in terms of $\partial_jf(\x)$ and $\partial_jg(\x)$.
%         \item \label{exr:19.30b}Compute $\partial_j(fg)(\x)$ in terms of $f(\x)$, $g(\x)$, $\partial_jf(\x)$, and $\partial_jg(\x)$.
%         \item \label{exr:19.30c}Compute $\partial_j(1/f)(\x)$ in terms of $\partial_jf(\x)$ and $f(\x)$. What assumption(s) do you need to make?
%         \item \label{exr:19.30d}Compute $\partial_j(f/g)(\x)$ in terms of $f(\x)$, $g(\x)$, $\partial_jf(\x)$, and $\partial_jg(\x)$. What assumption(s) do you need to make?
%     \end{enumerate}
%     Results \ref{exr:19.30a}, \ref{exr:19.30b}, and \ref{exr:19.30d} are known as the \textbf{Sum Rule}, the \textbf{Product Rule}, and the \textbf{Quotient Rule} (for partial derivatives), respectively.
%     (Hint: Use Proposition \ref{prp:19.25}.)
% \end{exercise}

% \begin{exercise}\label{exr:19.31}
%     For each of the following, find all given partial derivatives. No justification is required.
%     \begin{enumerate}[label={(\alph*)}]
%         \item $f(x,y)=x^2y+5x-6\e[y]x$.
%         \item $f(x,y,z)=\cos(z\e[xy])\sin(z^2)x$.
%     \end{enumerate}
% \end{exercise}

% We now consider functions $f:A\to\R^m$.




\end{document}